{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\S91001333\\AI_Projects\\LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_png.py:136\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\S91001333\\AI_Projects\\LangGraph\\.venv\\Lib\\site-packages\\pygraphviz\\__init__.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.13\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AGraph, Node, Edge, Attribute, ItemAttribute, DotError\n\u001b[0;32m     26\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAGraph\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEdge\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItemAttribute\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDotError\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\S91001333\\AI_Projects\\LangGraph\\.venv\\Lib\\site-packages\\pygraphviz\\agraph.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graphviz \u001b[38;5;28;01mas\u001b[39;00m gv\n\u001b[0;32m     18\u001b[0m _DEFAULT_ENCODING \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\S91001333\\AI_Projects\\LangGraph\\.venv\\Lib\\site-packages\\pygraphviz\\graphviz.py:10\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m __package__ \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _graphviz\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _graphviz: The specified module could not be found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m----> 3\u001b[0m Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\S91001333\\AI_Projects\\LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:401\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[1;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[0;32m    388\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    389\u001b[0m     node\u001b[38;5;241m.\u001b[39mid: node_data_str(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m    390\u001b[0m }\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m--> 401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\S91001333\\AI_Projects\\LangGraph\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\graph_png.py:138\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[1;34m(self, graph, output_path)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[0;32m    143\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"planner\": {\n",
      "        \"plan\": \"### Outline for Essay: \\\"The Difference Between LangChain and LangSmith\\\"\\n\\n#### I. Introduction\\n   A. Brief introduction to the importance of language models and tools in modern technology.\\n   B. Introduction to LangChain and LangSmith as prominent tools in the field.\\n   C. Thesis statement: While LangChain and LangSmith both serve to enhance language model capabilities, they differ significantly in their design, functionality, and use cases.\\n\\n#### II. Overview of LangChain\\n   A. Definition and Purpose\\n      1. Explanation of what LangChain is.\\n      2. Primary objectives and goals of LangChain.\\n   B. Key Features\\n      1. Core functionalities and features.\\n      2. Unique selling points.\\n   C. Use Cases\\n      1. Typical scenarios where LangChain is applied.\\n      2. Examples of industries or projects utilizing LangChain.\\n\\n#### III. Overview of LangSmith\\n   A. Definition and Purpose\\n      1. Explanation of what LangSmith is.\\n      2. Primary objectives and goals of LangSmith.\\n   B. Key Features\\n      1. Core functionalities and features.\\n      2. Unique selling points.\\n   C. Use Cases\\n      1. Typical scenarios where LangSmith is applied.\\n      2. Examples of industries or projects utilizing LangSmith.\\n\\n#### IV. Comparative Analysis\\n   A. Design and Architecture\\n      1. Comparison of the underlying design principles.\\n      2. Differences in architecture and technical frameworks.\\n   B. Functionality and Features\\n      1. Side-by-side comparison of key features.\\n      2. Analysis of strengths and weaknesses.\\n   C. User Experience and Accessibility\\n      1. Ease of use and learning curve.\\n      2. Community support and resources available.\\n   D. Performance and Scalability\\n      1. Performance metrics and benchmarks.\\n      2. Scalability and adaptability to different project sizes.\\n\\n#### V. Practical Implications\\n   A. Choosing the Right Tool\\n      1. Factors to consider when choosing between LangChain and LangSmith.\\n      2. Specific project requirements and how they align with each tool.\\n   B. Case Studies\\n      1. Real-world examples of successful implementations.\\n      2. Lessons learned from these case studies.\\n\\n#### VI. Future Prospects\\n   A. Evolution and Development\\n      1. Current trends in language model tools.\\n      2. Future developments and potential improvements for LangChain and LangSmith.\\n   B. Impact on the Industry\\n      1. How these tools are shaping the future of language models.\\n      2. Predictions for the next 5-10 years.\\n\\n#### VII. Conclusion\\n   A. Summary of key points discussed.\\n   B. Restatement of the thesis in light of the analysis.\\n   C. Final thoughts on the significance of understanding the differences between LangChain and LangSmith.\\n\\n### Notes and Instructions for Sections:\\n- **Introduction**: Ensure the introduction is engaging and provides enough context for readers unfamiliar with the topic.\\n- **Overview Sections**: Provide clear, concise definitions and avoid overly technical jargon. Use bullet points or subheadings to organize features and use cases.\\n- **Comparative Analysis**: Use tables or charts if necessary to visually represent comparisons. Be objective and balanced in discussing strengths and weaknesses.\\n- **Practical Implications**: Offer actionable insights and practical advice. Use real-world examples to illustrate points.\\n- **Future Prospects**: Incorporate expert opinions and predictions. Discuss potential technological advancements and their implications.\\n- **Conclusion**: Summarize without repeating information verbatim. Emphasize the importance of the topic and encourage further exploration.\\n\\nThis outline should provide a comprehensive framework for an essay that thoroughly explores the differences between LangChain and LangSmith, catering to both technical and non-technical audiences.\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"research_plan\": {\n",
      "        \"content\": [\n",
      "            \"Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses \\ud83d\\udc51 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you\\u2019re trying to figure out which tool fits your needs or you\\u2019re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here\\u2019s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou\\u2019re not limited to Python, though.\",\n",
      "            \"Find software to compare. Compare LangChain vs. LangSmith using this comparison chart. Compare price, features, and reviews of the software side-by-side to make the best choice for your business.\",\n",
      "            \"The Elastic AI Assistant for security supports the security analyst workflow with alert summarization, workflow suggestions, query generation and conversion, and more.\\n Built with LangChain\\nTeams building with LangChain are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.\\n Instabase AI Hub powers intelligent solutions that understand any type of document, execute custom business logic, facilitate human review at every step, and integrate with industry-specific systems to support business decisions.\\n Morningstar's Intelligence Engine Platform reads and recalls hundreds of thousands of research reports Morningstar produces and lets their customers ask questions to get unique market insights.\\n Realm-X automates critical real estate workflows and eliminates repetitive tasks, freeing up property managers to focus on more meaningful work like building resident connections and driving business performance.\\n\",\n",
      "            \"Rakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients\\nLangChain Partners with CommandBar on their Copilot User Assistant\\nLangChain partners with Elastic to launch the Elastic AI Assistant\\nAlly Financial Collaborates with LangChain to Deliver Coding Module to Mask PII\\nLLMs accelerate Adyen's support team through\\nsmart-ticket routing and support agent copilot\\nMorningstar Intelligence Engine puts personalized investment insights at analysts' fingertips\\nRobocorp\\u2019s code generation assistant makes building Python automation easy for developers\\nLangChain Expands Collaboration with Microsoft\\nHear from our happy customers\\nLangSmith helps teams of all sizes, across all industries, from ambitious\\nstartups to established enterprises.\\n We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.\\u201d\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. We couldn\\u2019t have achieved \\u00a0the product experience delivered to our customers without LangChain, and we couldn\\u2019t have done it at the same pace without LangSmith.\\u201d\\n\\u201cAs soon as we heard about LangSmith, we moved our entire development stack onto it. We couldn\\u2019t have achieved \\u00a0the product experience delivered to our customers without LangChain, and we couldn\\u2019t have done it at the same pace without LangSmith.\\u201d\\n\\u201cAs soon as we heard about LangSmith, we moved our entire development stack onto it. We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.\\u201d\\n\\u201cLangSmith helped us improve the accuracy and performance of Retool\\u2019s fine-tuned models.\",\n",
      "            \"Open a terminal or command prompt and navigate to your project directory. Type the following command and press Enter: yarn add langchain langsmith. This installs the necessary packages using yarn. If you prefer npm, use npm install langchain langsmith instead. Setting Up Your Environment. Create an API Key:\",\n",
      "            \"Quickstart. In this quickstart we'll show you how to: Get setup with LangChain, LangSmith and LangServe. Use the most basic and common components of LangChain: prompt templates, models, and output parsers. Use LangChain Expression Language, the protocol that LangChain is built on and which facilitates component chaining.\",\n",
      "            \"Click to download\\nTree Map reveals the Impact of NLP on 10 Industries\\nBased on the Innovation Map, the Tree Map below illustrates the impact of Natural Language Processing on 10 industries in 2023. Click to download\\nGlobal Startup Heat Map covers 2 398 NLP Startups & Scaleups\\nThe Global Startup Heat Map below highlights the global distribution of the 2 398 exemplary startups & scaleups that we analyzed for this research. The solution works with existing data without the need to port it, providing manufacturers a low-effort way to tap into the strengths of NLP and other enterprise AI technologies.\\n Created through the StartUs Insights Discovery Platform, the Heat Map reveals that the US has a high concentration of NLP startups, followed by the UK and India.\\n Innovation Map highlights Top NLP Startups impacting 10 Industries\\nFor this in-depth research on the Top Natural Langauge Processing Startups, we analyzed a sample of 2 398 global startups and scaleups.\",\n",
      "            \"Natural Language Processing ( NLP) is the area of artificial intelligence dealing with human language and speech. It sits at the crossroads between a diverse number of disciplines, from linguistics to computer science and engineering, and of course, AI. NLP involves teaching computers how to speak, write, listen to, and interpret human language.\",\n",
      "            \"Prompt templates in LangChain are predefined recipes for generating language model prompts. These templates include instructions, few-shot examples, and specific context and questions appropriate for a given task. This article provides a detailed guide on how to create and use prompt templates in LangChain, with examples and explanations.\",\n",
      "            \"On This Page\\nHow to Use LangChain Agents for Powerful Automated Tasks\\nPublished on 3/13/2024\\nIn the fascinating world of language models and automation, LangChain Agents stand out as a beacon of innovation, enabling developers and tech enthusiasts to create sophisticated, automated tasks that seem straight out of a sci-fi novel. LangChain Agents #2: OpenAI Functions Agent\\nThe OpenAI Functions agent is best suited for tasks where the model needs to decide whether and which function to call based on the input. Once you create your API key, you will need to export that as:\\nNow that we have populated our index that we will do doing retrieval over, we can easily turn it into a tool (the format needed for an agent to properly use it).\\n LangChain Agents #1: OpenAI Tools Agent\\nThe OpenAI Tools agent is designed to work seamlessly with the most recent OpenAI models, facilitating the execution of multiple functions or \\\"tools\\\" simultaneously. Although similar to the Tools agent, it's specifically designed for scenarios where function calling is central to the task, with OpenAI having deprecated this approach in favor of tools for newer models.\\n\",\n",
      "            \"How to write function in Python to reverse a string\\nHow to write SQL query to select users from a database by age\\nHow to implement binary search in Java\\nHow often do you have to break the flow, leave your IDE, and search for answers to questions (that are maybe similar to the ones above)? Table of Contents\\nMore on AI\\nHow AI code generation works\\nExplore the capabilities and benefits of AI code generation, and how it can improve the developer experience for your enterprise.\\n If the model labels it as positive, then you\\u2019d adjust the model\\u2019s parameters (variables that can be weighed or prioritized differently to change a model\\u2019s output) and try prompting it again to see if it can classify the sentiment as negative.\\n With GitHub Copilot Enterprise, organizations can tailor GitHub Copilot suggestions in the following ways:\\nCreate knowledge bases, which are Markdown files from a collection of repositories that provide GitHub Copilot with additional context through unstructured data, or data that doesn\\u2019t live in a database or spreadsheet.\\n More on AI Insights\\nHow AI code generation works\\nExplore the capabilities and benefits of AI code generation, and how it can improve the developer experience for your enterprise.\\n\",\n",
      "            \"Sign up\\nSign in\\nSign up\\nSign in\\nEvaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices\\nJane Huang\\nFollow\\nData Science at Microsoft\\n--\\n4\\nListen\\nShare\\nBy Jane Huang, Kirk Li and Daniel Yehdego\\nIn the ever-evolving landscape of Artificial Intelligence (AI), the development and deployment of Large Language Models (LLMs) have become pivotal in shaping intelligent applications across various domains. For example:\\nTable 4: RAI potential harm categories\\nReference: Empowering responsible AI practices | Microsoft AI\\nEvaluation metrics by application scenarios\\nWhen delving into the evaluation metrics of LLM systems, it is crucial to tailor the criteria based on the application scenarios to ensure a nuanced and context-specific assessment. Table 7 introduces traditional classification metrics, together with a new metrics InterpretEval.\\nTable 7: Sample metrics for NER\\nText-to-SQL\\nA practical text-to-SQL system\\u2019s effectiveness hinges on its ability to generalize proficiently across a broad spectrum of natural language questions, adapt to unseen database schemas seamlessly, and accommodate novel SQL query structures with agility. LLM evaluation versus LLM system evaluation\\nWhile this article focuses on the evaluation of LLM systems, it is crucial to discern the difference between assessing a standalone Large Language Model (LLM) and evaluating an LLM-based system. As we embark on a journey to explore the metrics, challenges, and best practices in evaluating LLM systems, it is imperative to recognize the significance of evaluation as an ongoing and dynamic process.\",\n",
      "            \"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter \\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n\\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: \\u201cwhat\\u2019s happening with my application?\\u201d\",\n",
      "            \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we\\u2019re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer\\u2019s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we\\u2019ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\",\n",
      "            \"Use cases. Walkthroughs of common end-to-end use cases. \\ud83d\\uddc3\\ufe0f SQL. 5 items. \\ud83d\\uddc3\\ufe0f Chatbots. 4 items. \\ud83d\\uddc3\\ufe0f Extraction. 3 items. \\ud83d\\uddc3\\ufe0f Query Analysis. 3 items. \\ud83d\\uddc3\\ufe0f Q&A with RAG. 8 items. \\ud83d\\uddc3\\ufe0f Tool use. 6 items. \\ud83d\\udcc4\\ufe0f Interacting with APIs. Lots of data and information is stored behind APIs. \\ud83d\\udcc4\\ufe0f Tabular Question Answering\",\n",
      "            \"Use cases. This section contains walkthroughs and techniques for common end-to-end use tasks. If you're looking to build something specific or are more of a hands-on learner, try one out! While they reference building blocks that are explained in greater detail in other sections, we absolutely encourage folks to get started by going through ...\",\n",
      "            \"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter \\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n\\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: \\u201cwhat\\u2019s happening with my application?\\u201d\",\n",
      "            \"Use Cases. The following guides are provided to serve as example use cases for how you can use LangSmith's production logging and automations. These are not meant to be exhaustive, nor are they optimized for your use case. They are meant as a reference to help you get started.\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"generate\": {\n",
      "        \"draft\": \"### The Difference Between LangChain and LangSmith\\n\\n#### I. Introduction\\nIn the rapidly evolving landscape of artificial intelligence, language models have become indispensable tools for a myriad of applications, from automating customer service to generating creative content. Among the prominent tools in this field are LangChain and LangSmith, each offering unique capabilities to enhance the functionality of large language models (LLMs). While both tools aim to optimize the use of LLMs, they differ significantly in their design, functionality, and use cases. This essay will explore these differences, providing a comprehensive understanding of what sets LangChain and LangSmith apart.\\n\\n#### II. Overview of LangChain\\n**A. Definition and Purpose**\\nLangChain is an open-source framework designed to facilitate the development of applications that leverage large language models like GPT-3. Its primary objective is to streamline the integration of LLMs into various applications, making it easier for developers to harness the power of these advanced models.\\n\\n**B. Key Features**\\n1. **Core Functionalities**: LangChain offers a range of core functionalities, including prompt templates, model integration, and output parsers. These components are designed to work seamlessly together, enabling developers to build sophisticated language model applications with minimal effort.\\n2. **Unique Selling Points**: One of the standout features of LangChain is its versatility. It supports multiple programming languages and can be integrated with various LLMs, making it a flexible choice for developers working on diverse projects.\\n\\n**C. Use Cases**\\n1. **Typical Scenarios**: LangChain is commonly used in scenarios that require the automation of complex tasks, such as generating personalized content, summarizing large volumes of text, and facilitating natural language interactions in chatbots.\\n2. **Industry Examples**: Industries such as finance, real estate, and customer service have successfully implemented LangChain to enhance their operations. For instance, Morningstar's Intelligence Engine uses LangChain to provide personalized investment insights to analysts.\\n\\n#### III. Overview of LangSmith\\n**A. Definition and Purpose**\\nLangSmith is a comprehensive platform designed to enhance the development, evaluation, and monitoring of language model applications. Its primary goal is to provide developers with the tools they need to build reliable and high-performing LLM-based systems.\\n\\n**B. Key Features**\\n1. **Core Functionalities**: LangSmith offers a suite of functionalities, including evaluation tools, performance monitoring, and debugging capabilities. These features are aimed at improving the accuracy and reliability of language model applications.\\n2. **Unique Selling Points**: LangSmith's unique selling point lies in its focus on evaluation and monitoring. It provides detailed insights into the performance of LLM applications, helping developers identify and address issues more efficiently.\\n\\n**C. Use Cases**\\n1. **Typical Scenarios**: LangSmith is particularly useful in scenarios where the accuracy and reliability of language model outputs are critical. This includes applications in healthcare, legal, and customer support, where incorrect or misleading information can have significant consequences.\\n2. **Industry Examples**: Companies like Rakuten Group and Ally Financial have leveraged LangSmith to enhance their LLM applications, ensuring that they deliver accurate and reliable results to their users.\\n\\n#### IV. Comparative Analysis\\n**A. Design and Architecture**\\n1. **Design Principles**: LangChain is designed with a focus on flexibility and ease of integration, supporting multiple languages and models. In contrast, LangSmith emphasizes robustness and reliability, with a strong focus on evaluation and monitoring.\\n2. **Technical Frameworks**: LangChain's architecture is modular, allowing developers to mix and match components as needed. LangSmith, on the other hand, offers a more integrated approach, with built-in tools for evaluation and monitoring.\\n\\n**B. Functionality and Features**\\n1. **Feature Comparison**: While both tools offer essential functionalities for building LLM applications, LangChain excels in its versatility and ease of use, whereas LangSmith stands out for its comprehensive evaluation and monitoring capabilities.\\n2. **Strengths and Weaknesses**: LangChain's strength lies in its flexibility, but it may require additional tools for evaluation and monitoring. LangSmith provides these tools out of the box but may have a steeper learning curve due to its comprehensive feature set.\\n\\n**C. User Experience and Accessibility**\\n1. **Ease of Use**: LangChain is generally easier to get started with, thanks to its modular design and extensive documentation. LangSmith, while powerful, may require more time to master due to its advanced features.\\n2. **Community Support**: Both tools have active communities and extensive resources available, including documentation, tutorials, and support channels.\\n\\n**D. Performance and Scalability**\\n1. **Performance Metrics**: LangChain and LangSmith both offer robust performance, but LangSmith's built-in evaluation tools provide more detailed insights into application performance.\\n2. **Scalability**: Both tools are scalable and can be adapted to projects of various sizes, but LangSmith's focus on monitoring makes it particularly well-suited for large-scale applications.\\n\\n#### V. Practical Implications\\n**A. Choosing the Right Tool**\\n1. **Factors to Consider**: When choosing between LangChain and LangSmith, developers should consider factors such as the complexity of their project, the need for evaluation and monitoring, and their familiarity with the tools.\\n2. **Project Requirements**: For projects that require flexibility and quick integration, LangChain may be the better choice. For applications where accuracy and reliability are paramount, LangSmith's comprehensive evaluation tools make it the preferred option.\\n\\n**B. Case Studies**\\n1. **Successful Implementations**: Companies like Morningstar and Rakuten Group have successfully implemented LangChain and LangSmith, respectively, to enhance their operations and deliver better results to their users.\\n2. **Lessons Learned**: These case studies highlight the importance of choosing the right tool for the job and the benefits of leveraging the unique strengths of each platform.\\n\\n#### VI. Future Prospects\\n**A. Evolution and Development**\\n1. **Current Trends**: The field of language model tools is rapidly evolving, with ongoing developments aimed at improving performance, scalability, and ease of use.\\n2. **Future Improvements**: Both LangChain and LangSmith are likely to see continued enhancements, with new features and capabilities being added to meet the growing demands of developers and users.\\n\\n**B. Impact on the Industry**\\n1. **Shaping the Future**: Tools like LangChain and LangSmith are playing a crucial role in shaping the future of language models, enabling the development of more sophisticated and reliable applications.\\n2. **Predictions**: Over the next 5-10 years, we can expect to see significant advancements in the capabilities of these tools, further driving innovation in the field of artificial intelligence.\\n\\n#### VII. Conclusion\\nIn summary, while LangChain and LangSmith both serve to enhance the capabilities of large language models, they differ significantly in their design, functionality, and use cases. LangChain offers flexibility and ease of integration, making it ideal for a wide range of applications. LangSmith, with its focus on evaluation and monitoring, is better suited for projects where accuracy and reliability are critical. Understanding these differences is essential for developers looking to choose the right tool for their specific needs, and both platforms are poised to continue playing a significant role in the future of language model applications.\",\n",
      "        \"revision_number\": 2\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"reflect\": {\n",
      "        \"critique\": \"### Critique and Recommendations\\n\\n#### Overall Impression\\nYour essay provides a comprehensive comparison between LangChain and LangSmith, covering various aspects such as design, functionality, use cases, and future prospects. The structure is logical, and the content is well-organized, making it easy to follow. However, there are areas where the essay could be improved to enhance clarity, depth, and engagement.\\n\\n#### Strengths\\n1. **Clear Structure**: The essay is well-structured with clear headings and subheadings, making it easy to navigate.\\n2. **Comprehensive Coverage**: You cover a wide range of aspects, from definitions and key features to use cases and future prospects.\\n3. **Comparative Analysis**: The comparative analysis section is particularly strong, providing a detailed comparison of the two tools.\\n\\n#### Areas for Improvement\\n1. **Depth of Analysis**: While the essay covers many aspects, some sections could benefit from deeper analysis. For example, the \\\"Key Features\\\" sections for both LangChain and LangSmith could include more detailed explanations and examples.\\n2. **Engagement and Style**: The essay is somewhat dry and technical. Adding more engaging language and real-world examples could make it more interesting to read.\\n3. **Length and Detail**: Some sections, such as \\\"Future Prospects\\\" and \\\"Practical Implications,\\\" could be expanded to provide more detailed insights and predictions.\\n4. **Citations and References**: Including citations and references to support your claims would add credibility to your essay.\\n\\n#### Detailed Recommendations\\n\\n1. **Introduction**\\n   - **Enhance Engagement**: Start with a compelling hook or anecdote to draw readers in. For example, you could mention a recent breakthrough in AI that highlights the importance of tools like LangChain and LangSmith.\\n   - **Thesis Statement**: Clearly state your thesis at the end of the introduction to set the stage for your analysis.\\n\\n2. **Overview of LangChain**\\n   - **Expand Key Features**: Provide more detailed explanations of the core functionalities and unique selling points. Include specific examples or case studies to illustrate how these features are used in real-world applications.\\n   - **Use Cases**: Add more industry-specific examples to show the versatility of LangChain. For instance, you could mention how LangChain is used in healthcare for patient data analysis or in education for personalized learning experiences.\\n\\n3. **Overview of LangSmith**\\n   - **Detailed Features**: Similar to LangChain, provide more in-depth explanations of LangSmith's core functionalities. Discuss how its evaluation and monitoring tools work and why they are important.\\n   - **Use Cases**: Include more detailed examples of how LangSmith is used in different industries. For example, you could describe how LangSmith helps in legal applications by ensuring the accuracy of legal document analysis.\\n\\n4. **Comparative Analysis**\\n   - **Technical Frameworks**: Provide more technical details about the architectures of LangChain and LangSmith. Discuss specific technologies or frameworks they use.\\n   - **User Experience**: Include user testimonials or quotes from developers who have used both tools to provide a more personal perspective.\\n\\n5. **Practical Implications**\\n   - **Case Studies**: Expand on the case studies by providing more detailed descriptions of the projects and the outcomes achieved. Discuss any challenges faced and how they were overcome.\\n   - **Decision-Making Factors**: Offer a more detailed guide on how to choose between LangChain and LangSmith based on specific project requirements. Include a decision matrix or checklist.\\n\\n6. **Future Prospects**\\n   - **Trends and Predictions**: Provide more detailed predictions about the future of language model tools. Discuss emerging trends, potential challenges, and opportunities for innovation.\\n   - **Impact on Industry**: Explore how advancements in LangChain and LangSmith could impact various industries. Include expert opinions or market analysis to support your predictions.\\n\\n7. **Conclusion**\\n   - **Summarize Key Points**: Briefly summarize the key points discussed in the essay. Reinforce the importance of understanding the differences between LangChain and LangSmith.\\n   - **Call to Action**: End with a call to action, encouraging developers to explore both tools and choose the one that best fits their needs.\\n\\n#### Final Thoughts\\nYour essay is a solid foundation that effectively compares LangChain and LangSmith. By incorporating the above recommendations, you can enhance the depth, engagement, and overall quality of your analysis. This will not only make your essay more informative but also more compelling for your readers.\"\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"research_critique\": {\n",
      "        \"content\": [\n",
      "            \"Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses \\ud83d\\udc51 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you\\u2019re trying to figure out which tool fits your needs or you\\u2019re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here\\u2019s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou\\u2019re not limited to Python, though.\",\n",
      "            \"Find software to compare. Compare LangChain vs. LangSmith using this comparison chart. Compare price, features, and reviews of the software side-by-side to make the best choice for your business.\",\n",
      "            \"The Elastic AI Assistant for security supports the security analyst workflow with alert summarization, workflow suggestions, query generation and conversion, and more.\\n Built with LangChain\\nTeams building with LangChain are driving operational efficiency, increasing discovery & personalization, and delivering premium products that generate revenue.\\n Instabase AI Hub powers intelligent solutions that understand any type of document, execute custom business logic, facilitate human review at every step, and integrate with industry-specific systems to support business decisions.\\n Morningstar's Intelligence Engine Platform reads and recalls hundreds of thousands of research reports Morningstar produces and lets their customers ask questions to get unique market insights.\\n Realm-X automates critical real estate workflows and eliminates repetitive tasks, freeing up property managers to focus on more meaningful work like building resident connections and driving business performance.\\n\",\n",
      "            \"Rakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients\\nLangChain Partners with CommandBar on their Copilot User Assistant\\nLangChain partners with Elastic to launch the Elastic AI Assistant\\nAlly Financial Collaborates with LangChain to Deliver Coding Module to Mask PII\\nLLMs accelerate Adyen's support team through\\nsmart-ticket routing and support agent copilot\\nMorningstar Intelligence Engine puts personalized investment insights at analysts' fingertips\\nRobocorp\\u2019s code generation assistant makes building Python automation easy for developers\\nLangChain Expands Collaboration with Microsoft\\nHear from our happy customers\\nLangSmith helps teams of all sizes, across all industries, from ambitious\\nstartups to established enterprises.\\n We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.\\u201d\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. We couldn\\u2019t have achieved \\u00a0the product experience delivered to our customers without LangChain, and we couldn\\u2019t have done it at the same pace without LangSmith.\\u201d\\n\\u201cAs soon as we heard about LangSmith, we moved our entire development stack onto it. We couldn\\u2019t have achieved \\u00a0the product experience delivered to our customers without LangChain, and we couldn\\u2019t have done it at the same pace without LangSmith.\\u201d\\n\\u201cAs soon as we heard about LangSmith, we moved our entire development stack onto it. We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.\\u201d\\n\\u201cLangSmith helped us improve the accuracy and performance of Retool\\u2019s fine-tuned models.\",\n",
      "            \"Open a terminal or command prompt and navigate to your project directory. Type the following command and press Enter: yarn add langchain langsmith. This installs the necessary packages using yarn. If you prefer npm, use npm install langchain langsmith instead. Setting Up Your Environment. Create an API Key:\",\n",
      "            \"Quickstart. In this quickstart we'll show you how to: Get setup with LangChain, LangSmith and LangServe. Use the most basic and common components of LangChain: prompt templates, models, and output parsers. Use LangChain Expression Language, the protocol that LangChain is built on and which facilitates component chaining.\",\n",
      "            \"Click to download\\nTree Map reveals the Impact of NLP on 10 Industries\\nBased on the Innovation Map, the Tree Map below illustrates the impact of Natural Language Processing on 10 industries in 2023. Click to download\\nGlobal Startup Heat Map covers 2 398 NLP Startups & Scaleups\\nThe Global Startup Heat Map below highlights the global distribution of the 2 398 exemplary startups & scaleups that we analyzed for this research. The solution works with existing data without the need to port it, providing manufacturers a low-effort way to tap into the strengths of NLP and other enterprise AI technologies.\\n Created through the StartUs Insights Discovery Platform, the Heat Map reveals that the US has a high concentration of NLP startups, followed by the UK and India.\\n Innovation Map highlights Top NLP Startups impacting 10 Industries\\nFor this in-depth research on the Top Natural Langauge Processing Startups, we analyzed a sample of 2 398 global startups and scaleups.\",\n",
      "            \"Natural Language Processing ( NLP) is the area of artificial intelligence dealing with human language and speech. It sits at the crossroads between a diverse number of disciplines, from linguistics to computer science and engineering, and of course, AI. NLP involves teaching computers how to speak, write, listen to, and interpret human language.\",\n",
      "            \"Prompt templates in LangChain are predefined recipes for generating language model prompts. These templates include instructions, few-shot examples, and specific context and questions appropriate for a given task. This article provides a detailed guide on how to create and use prompt templates in LangChain, with examples and explanations.\",\n",
      "            \"On This Page\\nHow to Use LangChain Agents for Powerful Automated Tasks\\nPublished on 3/13/2024\\nIn the fascinating world of language models and automation, LangChain Agents stand out as a beacon of innovation, enabling developers and tech enthusiasts to create sophisticated, automated tasks that seem straight out of a sci-fi novel. LangChain Agents #2: OpenAI Functions Agent\\nThe OpenAI Functions agent is best suited for tasks where the model needs to decide whether and which function to call based on the input. Once you create your API key, you will need to export that as:\\nNow that we have populated our index that we will do doing retrieval over, we can easily turn it into a tool (the format needed for an agent to properly use it).\\n LangChain Agents #1: OpenAI Tools Agent\\nThe OpenAI Tools agent is designed to work seamlessly with the most recent OpenAI models, facilitating the execution of multiple functions or \\\"tools\\\" simultaneously. Although similar to the Tools agent, it's specifically designed for scenarios where function calling is central to the task, with OpenAI having deprecated this approach in favor of tools for newer models.\\n\",\n",
      "            \"How to write function in Python to reverse a string\\nHow to write SQL query to select users from a database by age\\nHow to implement binary search in Java\\nHow often do you have to break the flow, leave your IDE, and search for answers to questions (that are maybe similar to the ones above)? Table of Contents\\nMore on AI\\nHow AI code generation works\\nExplore the capabilities and benefits of AI code generation, and how it can improve the developer experience for your enterprise.\\n If the model labels it as positive, then you\\u2019d adjust the model\\u2019s parameters (variables that can be weighed or prioritized differently to change a model\\u2019s output) and try prompting it again to see if it can classify the sentiment as negative.\\n With GitHub Copilot Enterprise, organizations can tailor GitHub Copilot suggestions in the following ways:\\nCreate knowledge bases, which are Markdown files from a collection of repositories that provide GitHub Copilot with additional context through unstructured data, or data that doesn\\u2019t live in a database or spreadsheet.\\n More on AI Insights\\nHow AI code generation works\\nExplore the capabilities and benefits of AI code generation, and how it can improve the developer experience for your enterprise.\\n\",\n",
      "            \"Sign up\\nSign in\\nSign up\\nSign in\\nEvaluating Large Language Model (LLM) systems: Metrics, challenges, and best practices\\nJane Huang\\nFollow\\nData Science at Microsoft\\n--\\n4\\nListen\\nShare\\nBy Jane Huang, Kirk Li and Daniel Yehdego\\nIn the ever-evolving landscape of Artificial Intelligence (AI), the development and deployment of Large Language Models (LLMs) have become pivotal in shaping intelligent applications across various domains. For example:\\nTable 4: RAI potential harm categories\\nReference: Empowering responsible AI practices | Microsoft AI\\nEvaluation metrics by application scenarios\\nWhen delving into the evaluation metrics of LLM systems, it is crucial to tailor the criteria based on the application scenarios to ensure a nuanced and context-specific assessment. Table 7 introduces traditional classification metrics, together with a new metrics InterpretEval.\\nTable 7: Sample metrics for NER\\nText-to-SQL\\nA practical text-to-SQL system\\u2019s effectiveness hinges on its ability to generalize proficiently across a broad spectrum of natural language questions, adapt to unseen database schemas seamlessly, and accommodate novel SQL query structures with agility. LLM evaluation versus LLM system evaluation\\nWhile this article focuses on the evaluation of LLM systems, it is crucial to discern the difference between assessing a standalone Large Language Model (LLM) and evaluating an LLM-based system. As we embark on a journey to explore the metrics, challenges, and best practices in evaluating LLM systems, it is imperative to recognize the significance of evaluation as an ongoing and dynamic process.\",\n",
      "            \"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter \\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n\\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: \\u201cwhat\\u2019s happening with my application?\\u201d\",\n",
      "            \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we\\u2019re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer\\u2019s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we\\u2019ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\",\n",
      "            \"Use cases. Walkthroughs of common end-to-end use cases. \\ud83d\\uddc3\\ufe0f SQL. 5 items. \\ud83d\\uddc3\\ufe0f Chatbots. 4 items. \\ud83d\\uddc3\\ufe0f Extraction. 3 items. \\ud83d\\uddc3\\ufe0f Query Analysis. 3 items. \\ud83d\\uddc3\\ufe0f Q&A with RAG. 8 items. \\ud83d\\uddc3\\ufe0f Tool use. 6 items. \\ud83d\\udcc4\\ufe0f Interacting with APIs. Lots of data and information is stored behind APIs. \\ud83d\\udcc4\\ufe0f Tabular Question Answering\",\n",
      "            \"Use cases. This section contains walkthroughs and techniques for common end-to-end use tasks. If you're looking to build something specific or are more of a hands-on learner, try one out! While they reference building blocks that are explained in greater detail in other sections, we absolutely encourage folks to get started by going through ...\",\n",
      "            \"BETA Sign Up\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter \\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n\\ud83e\\udd9c\\ud83d\\udd17 LangChain\\nBuild and deploy LLM apps with confidence\\nAn all-in-one developer platform for every step of the application lifecycle.\\n Prompt playground\\nCross-team collaboration\\nCatalog of ranging models & tasks\\nProven prompting strategies\\nExplore LangChain Hub\\nTurn the magic of LLM applications into enterprise-ready products\\nNative collaboration\\nBring your team together in LangSmith to craft prompts, debug, and capture feedback.\\n Application-level usage stats\\nFeedback collection\\nFilter traces\\nCost measurement\\nPerformance comparison\\nGo To Docs\\nManage Prompts\\nPrompts power your team's chains and agents, and LangSmith allows you to refine, test, and version them in one place. Dataset curation\\nEvaluate chain performance\\nAI-assisted evaluation\\nEasy benchmarking\\nGo To Docs\\nMonitor\\nGiven the stochastic nature of LLMs, it can be hard to answer the simple question: \\u201cwhat\\u2019s happening with my application?\\u201d\",\n",
      "            \"Use Cases. The following guides are provided to serve as example use cases for how you can use LangSmith's production logging and automations. These are not meant to be exhaustive, nor are they optimized for your use case. They are meant as a reference to help you get started.\",\n",
      "            \"Key Features of LangChain\\nLangChain boasts a range of features, such as:\\nAll of these features are designed to create an AI-powered language applications that can rival human intelligence, with the ultimate goal of achieving artificial general intelligence through the use of artificial neural networks, inspired by the complexity of the human brain and the intricacies of the human mind.\\n As continuous advancements in technology, integrations, and community contributions drive the evolution of what\\u2019s possible with large language models, we can expect LangChain to:\\nSummary\\nLangChain is revolutionizing the world of AI-powered language modeling, offering a modular framework that simplifies the development of AI-driven applications. Examples of these applications include:\\nThese real-world examples showcase the immense potential of LangChain and its ability to revolutionize the way we interact with AI-powered language models, creating a future where AI and human intelligence work together seamlessly to solve complex problems.\\n As we look to the future, LangChain and AI-powered language modeling will continue to evolve, shaping the landscape of AI and transforming the way we interact with the digital world.\\n These include:\\nLangChain Expression Language (LCEL)\\nLangChain Expression Language (LCEL) offers the following features:\\nLCEL assists developers in constructing composable chains, streamlining the coding process, and enabling them to create powerful AI-powered language applications with ease.\",\n",
      "            \"Langchain realworld examples in JS\\namalshehu/langchain-js-realworld\\nFolders and files\\nLatest commit\\nHistory\\ndata\\ndata\\nindexes\\nindexes\\nmodels\\nmodels\\nprompts\\nprompts\\nschema\\nschema\\nunstructured.io\\nunstructured.io\\nutils\\nutils\\n.gitignore\\n.gitignore\\nReadme.md\\nReadme.md\\nlangchain.md\\nlangchain.md\\npackage.json\\npackage.json\\npnpm-lock.yaml\\npnpm-lock.yaml\\nsample.env\\nsample.env\\nsetup.js\\nsetup.js\\nRepository files navigation\\nLangchain in Realworld\\nLangchain is a robust framework designed for incorporating Large Language Models (LLMs) into real-world applications. About\\nLangchain realworld examples in JS\\nTopics\\nResources\\nStars\\nWatchers\\nForks\\nReleases\\nPackages\\n0\\nLanguages\\nFooter\\nFooter navigation After calling the chain with a given input (\\\"Tell me about the history of the Roman Empire.\\\"), we're logging both the response from the AI model and the content of our ConversationSummaryMemory.\\nData Connections\\nIn an AI-powered legal tech application, users might need to search through extensive databases of legal documents. Processing the Chunks: For each chunk, we format the input, call the model with the input, parse the response using the statementParser, and add the parsed response to our results.\\n In this example:\\nSetting up the Parser: We first set up the StructuredOutputParser to parse the responses from the model based on a defined schema.\\n\",\n",
      "            \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\",\n",
      "            \"Monitor with Peace of Mind: Maintain application stability with LangSmith's real-time monitoring features. But LangSmith goes beyond just development. It equips you with the power to delve into your LLM application's inner workings. This allows you to: Debug with Precision: Troubleshoot complex issues efficiently with LangSmith's debugging tools.\",\n",
      "            \"yarn add langchain langsmith This installs the necessary packages using yarn. ... ChatPromptTemplate & StrOutputParser (might be custom): These sound like special tools you made ... We're creating a connection to a powerful language model called GPT-3.5-turbo. Think of it as the brain of the chatbot, responsible for generating responses.\",\n",
      "            \"Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses \\ud83d\\udc51 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you\\u2019re trying to figure out which tool fits your needs or you\\u2019re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here\\u2019s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou\\u2019re not limited to Python, though.\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"generate\": {\n",
      "        \"draft\": \"### The Difference Between LangChain and LangSmith\\n\\n#### I. Introduction\\nIn the rapidly evolving landscape of artificial intelligence, language models have become indispensable tools for a myriad of applications, from chatbots to complex data analysis. Among the prominent tools in this field are LangChain and LangSmith, both of which aim to enhance the capabilities of language models. However, despite their shared goal, they differ significantly in their design, functionality, and use cases. This essay will explore these differences, providing a comprehensive understanding of each tool and offering insights into their respective strengths and applications.\\n\\n#### II. Overview of LangChain\\nLangChain is a versatile open-source framework designed to facilitate the development of applications that utilize large language models (LLMs) like GPT-3. Its primary objective is to streamline the integration of LLMs into various applications, making it easier for developers to harness the power of advanced language models.\\n\\n**Key Features:**\\n1. **Modular Design:** LangChain offers a modular architecture that allows developers to build complex applications by chaining together different components.\\n2. **Prompt Templates:** These predefined recipes help generate language model prompts, including instructions, few-shot examples, and specific context for tasks.\\n3. **LangChain Expression Language (LCEL):** This protocol facilitates component chaining, making the coding process more efficient.\\n4. **Cross-Platform Compatibility:** While primarily used with Python, LangChain supports multiple programming languages.\\n\\n**Use Cases:**\\nLangChain is widely used in industries that require sophisticated language processing capabilities. For instance, Morningstar's Intelligence Engine leverages LangChain to analyze vast amounts of financial research reports, providing unique market insights. Similarly, Realm-X uses LangChain to automate real estate workflows, enhancing operational efficiency.\\n\\n#### III. Overview of LangSmith\\nLangSmith, on the other hand, is a comprehensive platform focused on the evaluation, testing, and monitoring of LLM applications. Its primary goal is to ensure the reliability and performance of language models in production environments.\\n\\n**Key Features:**\\n1. **Real-Time Monitoring:** LangSmith offers robust monitoring tools that provide real-time insights into the performance of LLM applications.\\n2. **Debugging Tools:** These tools help developers troubleshoot complex issues efficiently, ensuring the stability of their applications.\\n3. **Evaluation Metrics:** LangSmith provides a range of metrics to assess the accuracy and performance of language models.\\n4. **Collaboration Features:** The platform supports cross-team collaboration, allowing teams to refine, test, and version their prompts and models in one place.\\n\\n**Use Cases:**\\nLangSmith is particularly useful for teams that need to maintain high standards of accuracy and performance in their LLM applications. For example, Retool uses LangSmith to improve the accuracy of its fine-tuned models, while HelpHub leverages its monitoring features to ensure the quality of AI-generated responses.\\n\\n#### IV. Comparative Analysis\\n**Design and Architecture:**\\nLangChain's modular design focuses on flexibility and ease of integration, allowing developers to build complex applications by chaining components. In contrast, LangSmith's architecture is centered around evaluation and monitoring, providing tools to ensure the reliability of LLM applications.\\n\\n**Functionality and Features:**\\nWhile both tools offer unique features, LangChain excels in providing a framework for building applications, with its prompt templates and LCEL being standout features. LangSmith, however, shines in its evaluation and monitoring capabilities, offering real-time insights and robust debugging tools.\\n\\n**User Experience and Accessibility:**\\nLangChain's modular approach makes it accessible to developers looking to build and deploy LLM applications quickly. LangSmith, with its focus on evaluation and monitoring, may have a steeper learning curve but offers invaluable tools for maintaining application stability.\\n\\n**Performance and Scalability:**\\nLangChain is designed to be scalable, supporting a wide range of applications from small projects to large-scale deployments. LangSmith, while also scalable, is particularly suited for environments where performance and accuracy are critical, providing detailed metrics and real-time monitoring.\\n\\n#### V. Practical Implications\\n**Choosing the Right Tool:**\\nWhen deciding between LangChain and LangSmith, developers should consider their specific project requirements. LangChain is ideal for those looking to build and deploy LLM applications quickly, while LangSmith is better suited for teams that need to ensure the reliability and performance of their models.\\n\\n**Case Studies:**\\nMorningstar's use of LangChain to analyze financial reports and Retool's use of LangSmith to improve model accuracy are prime examples of how these tools can be effectively utilized. These case studies highlight the strengths of each tool and provide valuable lessons for other developers.\\n\\n#### VI. Future Prospects\\n**Evolution and Development:**\\nBoth LangChain and LangSmith are poised for significant advancements. As technology continues to evolve, we can expect these tools to incorporate new features and improvements, further enhancing their capabilities.\\n\\n**Impact on the Industry:**\\nLangChain and LangSmith are shaping the future of language models, driving innovation and setting new standards for AI-powered applications. In the next 5-10 years, these tools will likely play a pivotal role in the continued evolution of AI and its applications across various industries.\\n\\n#### VII. Conclusion\\nIn summary, while LangChain and LangSmith both aim to enhance the capabilities of language models, they do so in different ways. LangChain's modular framework and prompt templates make it an excellent choice for building applications, while LangSmith's evaluation and monitoring tools ensure the reliability and performance of LLM applications. Understanding these differences is crucial for developers looking to leverage the power of language models effectively. As these tools continue to evolve, they will undoubtedly shape the future of AI and its applications, driving innovation and transforming the way we interact with technology.\",\n",
      "        \"revision_number\": 3\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    prettified_output = json.dumps(s, indent=4)\n",
    "    print(prettified_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import ewriter, writer_gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MultiAgent = ewriter()\n",
    "app = writer_gui(MultiAgent.graph)\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
